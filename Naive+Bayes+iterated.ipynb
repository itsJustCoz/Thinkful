{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import scipy\n",
    "import sklearn\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import csv\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.metrics import confusion_matrix\n",
    "import random\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Classifier 1 -- 2000 positive words list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "metadata": {},
   "outputs": [],
   "source": [
    "amazon = pd.read_csv('amazon.txt', delimiter= '\\t', header=None)\n",
    "#import list of words associated with positive sentiments\n",
    "words = pd.read_csv('words.txt', delimiter = '\\n', header=None)\n",
    "\n",
    "#Create column labels\n",
    "amazon.columns = ['text', 'sentiment']\n",
    "\n",
    "#turn df to list and get rid of first word as it's casuing problems.\n",
    "words = words[0].tolist()\n",
    "keywords = words[1:]\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "for key in keywords:\n",
    "    amazon[str(key)] = amazon.text.str.contains(\n",
    "        str(key),\n",
    "        case=False\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "amazon['sentiment'] = (amazon['sentiment'] == 1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data = amazon[keywords]\n",
    "target = amazon['sentiment']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of mislabeled points out of a total 1000 points : 166\n",
      "With 20% Holdout: 0.765\n",
      "Testing on Sample: 0.834\n"
     ]
    }
   ],
   "source": [
    "# Our data is binary / boolean, so we're importing the Bernoulli classifier.\n",
    "from sklearn.naive_bayes import BernoulliNB\n",
    "\n",
    "# Instantiate our model and store it in a new variable.\n",
    "bnb = BernoulliNB()\n",
    "\n",
    "# Fit our model to the data.\n",
    "bnb.fit(data, target)\n",
    "\n",
    "# Classify, storing the result in a new variable.\n",
    "y_pred = bnb.predict(data)\n",
    "\n",
    "# Display our results.\n",
    "print(\"Number of mislabeled points out of a total {} points : {}\".format(\n",
    "    data.shape[0],\n",
    "    (target != y_pred).sum()\n",
    "))\n",
    "\n",
    "# Use train_test_split to create the necessary training and test groups\n",
    "X_train, X_test, y_train, y_test = train_test_split(data, target, test_size=0.2, random_state=20)\n",
    "print('With 20% Holdout: ' + str(bnb.fit(X_train, y_train).score(X_test, y_test)))\n",
    "print('Testing on Sample: ' + str(bnb.fit(data, target).score(data, target)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 0.84  0.81  0.84  0.77  0.79  0.72  0.72  0.73  0.85  0.74]\n",
      "[[455  45]\n",
      " [121 379]]\n"
     ]
    }
   ],
   "source": [
    "print(cross_val_score(bnb, data, target, cv=10))\n",
    "print(confusion_matrix(target, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "455 predicted Bad/Actual Bad (True Negative)<br>\n",
    "45  predicted Good/ Actual Bad (False Positive - Type 1)<br>\n",
    "121 Predicted Bad/ Actual Good (False Negative - Type 2)<br>\n",
    "379 Predicted Good/ Actual Good(True Positive)<br>\n",
    "<br>\n",
    "75% of positives indentified.<br>\n",
    "91% of negatives indentified.<br>\n",
    "<br>\n",
    "This classifier has the highest accuracy rate, but suffers from some overfitting with a 12% difference in the highest and lowest group."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Classifier 2 -- Shorter focused list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {},
   "outputs": [],
   "source": [
    "amazon = pd.read_csv('amazon.txt', delimiter= '\\t', header=None)\n",
    "\n",
    "#Create column labels\n",
    "amazon.columns = ['text', 'sentiment']\n",
    "\n",
    "keywords = ['great', 'awesome', 'like', 'happy', 'good', 'quality', 'amazing']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "for key in keywords:\n",
    "    amazon[str(key)] = amazon.text.str.contains(\n",
    "        str(key),\n",
    "        case=False\n",
    "    )\n",
    "\n",
    "amazon['sentiment'] = (amazon['sentiment'] == 1)\n",
    "data = amazon[keywords]\n",
    "target = amazon['sentiment']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of mislabeled points out of a total 1000 points : 351\n",
      "With 20% Holdout: 0.64\n",
      "Testing on Sample: 0.649\n"
     ]
    }
   ],
   "source": [
    "# Our data is binary / boolean, so we're importing the Bernoulli classifier.\n",
    "from sklearn.naive_bayes import BernoulliNB\n",
    "\n",
    "# Instantiate our model and store it in a new variable.\n",
    "bnb = BernoulliNB()\n",
    "\n",
    "# Fit our model to the data.\n",
    "bnb.fit(data, target)\n",
    "\n",
    "# Classify, storing the result in a new variable.\n",
    "y_pred = bnb.predict(data)\n",
    "\n",
    "# Display our results.\n",
    "print(\"Number of mislabeled points out of a total {} points : {}\".format(\n",
    "    data.shape[0],\n",
    "    (target != y_pred).sum()\n",
    "))\n",
    "\n",
    "# Use train_test_split to create the necessary training and test groups\n",
    "X_train, X_test, y_train, y_test = train_test_split(data, target, test_size=0.2, random_state=20)\n",
    "print('With 20% Holdout: ' + str(bnb.fit(X_train, y_train).score(X_test, y_test)))\n",
    "print('Testing on Sample: ' + str(bnb.fit(data, target).score(data, target)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 0.67  0.65  0.68  0.67  0.64  0.69  0.61  0.59  0.64  0.62]\n",
      "[[448  52]\n",
      " [299 201]]\n"
     ]
    }
   ],
   "source": [
    "print(cross_val_score(bnb, data, target, cv=10))\n",
    "print(confusion_matrix(target, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "448 predicted Bad/Actual Bad (True Negative)<br>\n",
    "52  predicted Good/ Actual Bad (False Positive - Type 1)<br>\n",
    "299 Predicted Bad/ Actual Good (False Negative - Type 2)<br>\n",
    "201 Predicted Good/ Actual Good(True Positive)<br>\n",
    "<br>\n",
    "40% of positives indentified.<br>\n",
    "87% of negatives indentified.<br>\n",
    "<br>\n",
    "<br>\n",
    "I still get a large difference between groups, but the number of errors almost doubles. The increase comes mostly from type 2 errors."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Classifier 3 -- Shorter word list with length feature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "metadata": {},
   "outputs": [],
   "source": [
    "amazon = pd.read_csv('amazon.txt', delimiter= '\\t', header=None)\n",
    "#import list of words associated with positive sentiment\n",
    "\n",
    "#Create column labels\n",
    "amazon.columns = ['text', 'sentiment']\n",
    "\n",
    "keywords = ['great', 'awesome', 'like', 'happy', 'good', 'quality', 'amazing']\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {},
   "outputs": [],
   "source": [
    "for key in keywords:\n",
    "    amazon[str(key)] = amazon.text.str.contains(\n",
    "        str(key),\n",
    "        case=False\n",
    "    )\n",
    "\n",
    "amazon['length'] = amazon['text'].apply(lambda x: True if len(x)<30 else False)\n",
    "#amazon['length'] = amazon.apply(lambda x: True if len(str(x)< 12 else False))\n",
    "#df['name_length']  = df['seller_name'].str.len()\n",
    "\n",
    "\n",
    "amazon['sentiment'] = (amazon['sentiment'] == 1)\n",
    "data = amazon[keywords +['length']]\n",
    "\n",
    "target = amazon['sentiment']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of mislabeled points out of a total 1000 points : 357\n",
      "With 20% Holdout: 0.635\n",
      "Testing on Sample: 0.643\n"
     ]
    }
   ],
   "source": [
    "# Instantiate our model and store it in a new variable.\n",
    "bnb = BernoulliNB()\n",
    "\n",
    "# Fit our model to the data.\n",
    "bnb.fit(data, target)\n",
    "\n",
    "# Classify, storing the result in a new variable.\n",
    "y_pred = bnb.predict(data)\n",
    "\n",
    "# Display our results.\n",
    "print(\"Number of mislabeled points out of a total {} points : {}\".format(\n",
    "    data.shape[0],\n",
    "    (target != y_pred).sum()\n",
    "))\n",
    "\n",
    "# Use train_test_split to create the necessary training and test groups\n",
    "X_train, X_test, y_train, y_test = train_test_split(data, target, test_size=0.2, random_state=20)\n",
    "print('With 20% Holdout: ' + str(bnb.fit(X_train, y_train).score(X_test, y_test)))\n",
    "print('Testing on Sample: ' + str(bnb.fit(data, target).score(data, target)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 0.67  0.66  0.68  0.67  0.62  0.68  0.59  0.56  0.63  0.61]\n",
      "[[459  41]\n",
      " [316 184]]\n"
     ]
    }
   ],
   "source": [
    "print(cross_val_score(bnb, data, target, cv=10))\n",
    "print(confusion_matrix(target, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "459 predicted Bad/Actual Bad (True Negative) <br>\n",
    "41  predicted Good/ Actual Bad (False Positive - Type 1) <br>\n",
    "316 Predicted Bad/ Actual Good (False Negative - Type 2)<br>\n",
    "184 Predicted Good/ Actual Good(True Positive)<br>\n",
    "<br>\n",
    "37% of positives indentified.<br>\n",
    "92% of negatives indentified.<br>\n",
    "<br>\n",
    "<br>\n",
    "Introducing a length feature further increases type 2 errors and has the same overfitting issues."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Classifier 4 -- Slimmed down word list from classifier 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [],
   "source": [
    "amazon = pd.read_csv('amazon.txt', delimiter= '\\t', header=None)\n",
    "#import list of words associated with positive sentiments\n",
    "words = pd.read_csv('words.txt', delimiter = '\\n', header=None)\n",
    "\n",
    "\n",
    "#Create column labels\n",
    "amazon.columns = ['text', 'sentiment']\n",
    "\n",
    "#turn df to list and get rid of first word as it's casuing problems.\n",
    "words = words[0].tolist()\n",
    "keywords = words[1:]\n",
    "random.shuffle(keywords)\n",
    "keywords = keywords[:500]\n",
    "\n",
    "for key in keywords:\n",
    "    amazon[str(key)] = amazon.text.str.contains(\n",
    "        str(key),\n",
    "        case=False\n",
    "    )\n",
    "    \n",
    "amazon['sentiment'] = (amazon['sentiment'] == 1)\n",
    "data = amazon[keywords]\n",
    "\n",
    "target = amazon['sentiment']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of mislabeled points out of a total 1000 points : 328\n",
      "With 20% Holdout: 0.655\n",
      "Testing on Sample: 0.672\n"
     ]
    }
   ],
   "source": [
    "# Instantiate our model and store it in a new variable.\n",
    "bnb = BernoulliNB()\n",
    "\n",
    "# Fit our model to the data.\n",
    "bnb.fit(data, target)\n",
    "\n",
    "# Classify, storing the result in a new variable.\n",
    "y_pred = bnb.predict(data)\n",
    "\n",
    "# Display our results.\n",
    "print(\"Number of mislabeled points out of a total {} points : {}\".format(\n",
    "    data.shape[0],\n",
    "    (target != y_pred).sum()\n",
    "))\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "# Use train_test_split to create the necessary training and test groups\n",
    "X_train, X_test, y_train, y_test = train_test_split(data, target, test_size=0.2, random_state=20)\n",
    "print('With 20% Holdout: ' + str(bnb.fit(X_train, y_train).score(X_test, y_test)))\n",
    "print('Testing on Sample: ' + str(bnb.fit(data, target).score(data, target)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 0.68  0.62  0.63  0.66  0.66  0.63  0.59  0.58  0.69  0.63]\n",
      "[[462  38]\n",
      " [290 210]]\n"
     ]
    }
   ],
   "source": [
    "print(cross_val_score(bnb, data, target, cv=10))\n",
    "print(confusion_matrix(target, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "462 predicted Bad/Actual Bad (True Negative)<br>\n",
    "38  predicted Good/ Actual Bad (False Positive - Type 1)<br>\n",
    "290 Predicted Bad/ Actual Good (False Negative - Type 2)<br>\n",
    "210 Predicted Good/ Actual Good(True Positive)<br>\n",
    "<br>\n",
    "42% of positives indentified.<br>\n",
    "92% of negatives indentified.<br>\n",
    "<br>\n",
    "<br>\n",
    "I cut the original word list down to 500 randomly selected words from the initial 2000 word list. This performs better than the previous 2, but not as well as the initial classifier. We get a slight reduction in type 1 errors, with a large increase in type 2 errors. Overfitting is still a problem."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Classifier 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "amazon = pd.read_csv('amazon.txt', delimiter= '\\t', header=None)\n",
    "#import list of words associated with positive sentiments\n",
    "words = pd.read_csv('words.txt', delimiter = '\\n', header=None)\n",
    "\n",
    "\n",
    "#Create column labels\n",
    "amazon.columns = ['text', 'sentiment']\n",
    "\n",
    "#turn df to list and get rid of first word as it's casuing problems.\n",
    "words = words[0].tolist()\n",
    "keywords = words[1:]\n",
    "random.shuffle(keywords)\n",
    "keywords = keywords[:1000]\n",
    "\n",
    "for key in keywords:\n",
    "    amazon[str(key)] = amazon.text.str.contains(\n",
    "        str(key),\n",
    "        case=False\n",
    "    )\n",
    "    \n",
    "amazon['sentiment'] = (amazon['sentiment'] == 1)\n",
    "data = amazon[keywords]\n",
    "\n",
    "target = amazon['sentiment']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of mislabeled points out of a total 1000 points : 225\n",
      "With 20% Holdout: 0.725\n",
      "Testing on Sample: 0.775\n"
     ]
    }
   ],
   "source": [
    "# Instantiate our model and store it in a new variable.\n",
    "bnb = BernoulliNB()\n",
    "\n",
    "# Fit our model to the data.\n",
    "bnb.fit(data, target)\n",
    "\n",
    "# Classify, storing the result in a new variable.\n",
    "y_pred = bnb.predict(data)\n",
    "\n",
    "# Display our results.\n",
    "print(\"Number of mislabeled points out of a total {} points : {}\".format(\n",
    "    data.shape[0],\n",
    "    (target != y_pred).sum()\n",
    "))\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "# Use train_test_split to create the necessary training and test groups\n",
    "X_train, X_test, y_train, y_test = train_test_split(data, target, test_size=0.2, random_state=20)\n",
    "print('With 20% Holdout: ' + str(bnb.fit(X_train, y_train).score(X_test, y_test)))\n",
    "print('Testing on Sample: ' + str(bnb.fit(data, target).score(data, target)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 0.83  0.77  0.77  0.77  0.76  0.76  0.69  0.64  0.81  0.66]\n",
      "[[462  38]\n",
      " [187 313]]\n"
     ]
    }
   ],
   "source": [
    "print(cross_val_score(bnb, data, target, cv=10))\n",
    "print(confusion_matrix(target, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "462 predicted Bad/Actual Bad (True Negative) <br>\n",
    "38  predicted Good/Actual Bad (False Positive - Type 1)<br>\n",
    "313 Predicted Bad/Actual Good (False Negative - Type 2)<br>\n",
    "184 Predicted Good/Actual Good(True Positive)<br>\n",
    "<br>\n",
    "37% of positives indentified.<br>\n",
    "92% of negatives indentified.<br>\n",
    "<br>\n",
    "A slight variation of classifier 4, cutting the original word list down to 1000 words. This performs better than all classifiers except the first. There is a slight reduction in type 1 errors, with a large increase in type 2 errors. Overfitting is still a problem."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conclusion"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The first classifier was the most accurate and while it suffered from overfitting problems, the overfitting was present in all the other classifiers despite some of the classifiers being half as accurate. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
